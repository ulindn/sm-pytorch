{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local PyTorch models using SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses PyTorch quick start tutotial (https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and trains a model using Amazon SageMaker Python SDK (https://sagemaker.readthedocs.io/en/stable/index.html) as in Amazon SageMaker Examples (https://github.com/aws/amazon-sagemaker-examples/tree/main/frameworks/pytorch) using Fashion MNIST dataset. The model can be trained in two ways: by running the prebuilt AWS SageMaker Pytorch container in AWS or by running it locally. For inference, the model is tested locally.\n",
    "\n",
    "The development and test environment used was:\n",
    "- Ubuntu with Docker Compose v2\n",
    "- VSCode with conda and tensorboard \n",
    "\n",
    "#### References\n",
    "- https://github.com/aws/amazon-sagemaker-examples/blob/main/frameworks/pytorch/get_started_mnist_train.ipynb\n",
    "- https://github.com/aws/amazon-sagemaker-examples/tree/main/frameworks/pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example runs from notebook and does not have a UI. \n",
    "# Data is downloaded to S3 and fetched by the container during training.\n",
    "# After training, the container saves the model to S3. After training, the model is manually downloaded to test inference\n",
    "\n",
    "# Tensorboard is used to monitor training progress. It can be viewed in the browser or in VSCode using the Tensorboard extension.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directories and Files are:\n",
    "# ./code_local/: local directory containing python scripts\n",
    "# ./code_local/dataset.py: dataset definition using PyTorch Fashion MNIST dataset\n",
    "# ./code_local/model_def.py: model definition using PyTorch nn.Module\n",
    "# ./code_local/train.py: training script used by SM container  \n",
    "\n",
    "# ./data/: Fashion MNIST dataset is downloaded here\n",
    "# ./out_model/: trained model is saved here after manual download\n",
    "# ./runs/: tensorboard logs are saved here\n",
    "\n",
    "# ./env_sm_pytorch.yml: conda environment file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment as Local or SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "## Set training mode\n",
    "# Set local_training to True to run the SageMaker container for training on the machine that runs this notebook\n",
    "# Set local_traiing to False to run the SageMaker container for training script in AWS\n",
    "local_training = False\n",
    "\n",
    "## Set inference mode\n",
    "# Set local_inference to True to run the SageMaker container for inference endpoint on the machine that runs this notebook. \n",
    "# Set local_inference to False to run the inference endpoint in AWS\n",
    "# local_inference = True\n",
    "\n",
    "# For local training or local inference, docker is needed to run SageMaker containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp SageMaker Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.75.1\n",
      "SageMaker session:<sagemaker.session.Session object at 0x7f9982436ef0>\n",
      "SageMaker region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# uses ~/.aws/credentials and ~/.aws/config\n",
    "identity = boto3.client('sts').get_caller_identity()\n",
    "user_name = identity['Arn'].split(':')[5]\n",
    "sm_session = sagemaker.Session()\n",
    "sm_region = sm_session.boto_region_name\n",
    "bucket = sm_session.default_bucket()\n",
    "\n",
    "# SageMaker (SM) role is in format like \"arn:aws:iam::111222333444:role/service-role/AmazonSageMaker-ExecutionRole-999900001111222\"\n",
    "# Get role using role = get_execution_role() or copy it from the console.\n",
    "# Since this notebook runs on a local laptop, the role is set in a file with custom environment variables\n",
    "dir_home = os.environ['HOME']\n",
    "env_file = dir_home + '/.aws/env_custom'\n",
    "load_dotenv(env_file)\n",
    "role = os.getenv('role')\n",
    "\n",
    "prefix = \"DEMO-fashion-mnist-pytorch\"\n",
    "output_path = \"s3://\" + sm_session.default_bucket() + \"/\" + prefix\n",
    "\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoint-{}'.format(bucket, checkpoint_suffix)\n",
    "\n",
    "# uncomment to print the values\n",
    "# print(f'User name: {user_name}')\n",
    "print(f'SageMaker version: {sagemaker.__version__}')\n",
    "print(f'SageMaker session:{sm_session}')\n",
    "print(f'SageMaker region: {sm_region}')\n",
    "# print(f'SageMaker S3 bucket: {bucket}')\n",
    "# print(f'SageMaker S3 bucket output path: {output_path}')\n",
    "# print('Checkpointing Path: {}'.format(checkpoint_s3_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channels\n",
    "loc = sm_session.upload_data(path=\"./data\", bucket=bucket, key_prefix=prefix)\n",
    "channels = {\"training\": loc, \"testing\": loc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cpu\n"
     ]
    }
   ],
   "source": [
    "# set device  \n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device is: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the estimator\n",
    "if local_training:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"code_local\",   \n",
    "    role=role,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size=250,\n",
    "    output_path=output_path,\n",
    "    hyperparameters={\"batch-size\": 128, \"epochs\": 5, \"learning-rate\": 1e-3, \"log-interval\": 100},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# uncomment capture before running to see the training log\n",
    "# train. This downloads SM container in the instance_type and runs the training script provided in estimator's entry_point\n",
    "estimator.fit(inputs=channels)\n",
    "#check S3 bucket for the model.tar.gz file in output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# model artifact is saved in S3\n",
    "# uncomment capture and run the cell to see the S3 folder in which the model is saved\n",
    "pt_fmnist_model_data = estimator.model_data\n",
    "print(\"Model artifact saved at:\\n\", pt_fmnist_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# get data for inference. In this case, it is the same as test data\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "infer_data = datasets.FashionMNIST(\n",
    "            root=\"data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=ToTensor(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for Fashion MNIST dataset\n",
    "classes={\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually download the model (model.tar.gz) from S3 into local folder out_model and extract model.pth file from the tar.gz file\n",
    "local_model_folder_file = './out_model/' + \"model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: \"Ankle Boot\", Actual Class: \"Ankle Boot\"\n"
     ]
    }
   ],
   "source": [
    "# make a single prediction\n",
    "import numpy as np\n",
    "from code_local import model_def\n",
    "\n",
    "model_inf = model_def.NeuralNetwork()\n",
    "model_inf.load_state_dict(torch.load(local_model_folder_file))\n",
    "model_inf.to(device).eval()\n",
    "\n",
    "x = infer_data[0][0]\n",
    "y = infer_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model_inf(x)\n",
    "    pred_index = np.argmax(pred[0])\n",
    "    value = pred_index.item()\n",
    "    predicted = classes[value]\n",
    "    actual = classes[y]\n",
    "    print(f'Predicted Class: \"{predicted}\", Actual Class: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: \"Dress\", Actual Class: \"Dress\"\n",
      "Predicted Class: \"Ankle Boot\", Actual Class: \"Ankle Boot\"\n",
      "Predicted Class: \"Trouser\", Actual Class: \"Trouser\"\n",
      "Predicted Class: \"Coat\", Actual Class: \"Pullover\"\n",
      "Predicted Class: \"Bag\", Actual Class: \"Bag\"\n",
      "Predicted Class: \"Bag\", Actual Class: \"Sandal\"\n",
      "Predicted Class: \"Bag\", Actual Class: \"Bag\"\n",
      "Predicted Class: \"Trouser\", Actual Class: \"Trouser\"\n",
      "Predicted Class: \"Pullover\", Actual Class: \"T-shirt\"\n",
      "Predicted Class: \"Trouser\", Actual Class: \"Trouser\"\n"
     ]
    }
   ],
   "source": [
    "# make predictions on randomly selected examples\n",
    "import random\n",
    "\n",
    "length = len(infer_data)\n",
    "num_samples = 10\n",
    "random_rows = random.sample(range(length), num_samples)\n",
    "\n",
    "# get the class names for these random rows\n",
    "for i in random_rows:\n",
    "    x = infer_data[i][0]\n",
    "    y = infer_data[i][1]\n",
    "    with torch.no_grad():\n",
    "        pred = model_inf(x)\n",
    "        pred_index = np.argmax(pred[0])\n",
    "        value = pred_index.item()\n",
    "        predicted = classes[value]\n",
    "        actual = classes[y]\n",
    "        print(f'Predicted Class: \"{predicted}\", Actual Class: \"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm_img_clfy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
